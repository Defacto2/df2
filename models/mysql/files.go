// Code generated by SQLBoiler 4.16.1 (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package models

import (
	"context"
	"database/sql"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/friendsofgo/errors"
	"github.com/volatiletech/null/v8"
	"github.com/volatiletech/sqlboiler/v4/boil"
	"github.com/volatiletech/sqlboiler/v4/queries"
	"github.com/volatiletech/sqlboiler/v4/queries/qm"
	"github.com/volatiletech/sqlboiler/v4/queries/qmhelper"
	"github.com/volatiletech/strmangle"
)

// File is an object representing the database table.
type File struct { // Primary key
	ID int `boil:"id" json:"id" toml:"id" yaml:"id"`
	// Global identifier
	UUID null.String `boil:"uuid" json:"uuid,omitempty" toml:"uuid" yaml:"uuid,omitempty"`
	// List of associated records
	ListRelations null.String `boil:"list_relations" json:"list_relations,omitempty" toml:"list_relations" yaml:"list_relations,omitempty"`
	// URI for a 16colo.rs page
	WebID16colors null.String `boil:"web_id_16colors" json:"web_id_16colors,omitempty" toml:"web_id_16colors" yaml:"web_id_16colors,omitempty"`
	// Id for a GitHub repository
	WebIDGithub null.String `boil:"web_id_github" json:"web_id_github,omitempty" toml:"web_id_github" yaml:"web_id_github,omitempty"`
	// Id for a related YouTube video
	WebIDYoutube null.String `boil:"web_id_youtube" json:"web_id_youtube,omitempty" toml:"web_id_youtube" yaml:"web_id_youtube,omitempty"`
	// Id for a PouÃ«t record
	WebIDPouet null.Int `boil:"web_id_pouet" json:"web_id_pouet,omitempty" toml:"web_id_pouet" yaml:"web_id_pouet,omitempty"`
	// Id for a Demozoo record
	WebIDDemozoo null.Int `boil:"web_id_demozoo" json:"web_id_demozoo,omitempty" toml:"web_id_demozoo" yaml:"web_id_demozoo,omitempty"`
	// Group or brand used to credit the file
	GroupBrandFor null.String `boil:"group_brand_for" json:"group_brand_for,omitempty" toml:"group_brand_for" yaml:"group_brand_for,omitempty"`
	// Optional alternative Group or brand used to credit the file
	GroupBrandBy null.String `boil:"group_brand_by" json:"group_brand_by,omitempty" toml:"group_brand_by" yaml:"group_brand_by,omitempty"`
	// Display title or magazine edition
	RecordTitle null.String `boil:"record_title" json:"record_title,omitempty" toml:"record_title" yaml:"record_title,omitempty"`
	// Published date year
	DateIssuedYear null.Int16 `boil:"date_issued_year" json:"date_issued_year,omitempty" toml:"date_issued_year" yaml:"date_issued_year,omitempty"`
	// Published date month
	DateIssuedMonth null.Int8 `boil:"date_issued_month" json:"date_issued_month,omitempty" toml:"date_issued_month" yaml:"date_issued_month,omitempty"`
	// Published date day
	DateIssuedDay null.Int8 `boil:"date_issued_day" json:"date_issued_day,omitempty" toml:"date_issued_day" yaml:"date_issued_day,omitempty"`
	// Writing credits
	CreditText null.String `boil:"credit_text" json:"credit_text,omitempty" toml:"credit_text" yaml:"credit_text,omitempty"`
	// Programming credits
	CreditProgram null.String `boil:"credit_program" json:"credit_program,omitempty" toml:"credit_program" yaml:"credit_program,omitempty"`
	// Artist credits
	CreditIllustration null.String `boil:"credit_illustration" json:"credit_illustration,omitempty" toml:"credit_illustration" yaml:"credit_illustration,omitempty"`
	// Composer credits
	CreditAudio null.String `boil:"credit_audio" json:"credit_audio,omitempty" toml:"credit_audio" yaml:"credit_audio,omitempty"`
	// File name
	Filename null.String `boil:"filename" json:"filename,omitempty" toml:"filename" yaml:"filename,omitempty"`
	// Size of the file in bytes
	Filesize null.Int `boil:"filesize" json:"filesize,omitempty" toml:"filesize" yaml:"filesize,omitempty"`
	// List of URLs related to this file
	ListLinks null.String `boil:"list_links" json:"list_links,omitempty" toml:"list_links" yaml:"list_links,omitempty"`
	// URL showing results of a virus scan
	FileSecurityAlertURL null.String `boil:"file_security_alert_url" json:"file_security_alert_url,omitempty" toml:"file_security_alert_url" yaml:"file_security_alert_url,omitempty"`
	// Content of archive
	FileZipContent null.String `boil:"file_zip_content" json:"file_zip_content,omitempty" toml:"file_zip_content" yaml:"file_zip_content,omitempty"`
	// File type meta data
	FileMagicType null.String `boil:"file_magic_type" json:"file_magic_type,omitempty" toml:"file_magic_type" yaml:"file_magic_type,omitempty"`
	// Internal file to use as a screenshot
	PreviewImage null.String `boil:"preview_image" json:"preview_image,omitempty" toml:"preview_image" yaml:"preview_image,omitempty"`
	// SHA384 hash of file
	FileIntegrityStrong null.String `boil:"file_integrity_strong" json:"file_integrity_strong,omitempty" toml:"file_integrity_strong" yaml:"file_integrity_strong,omitempty"`
	// MD5 hash of file
	FileIntegrityWeak null.String `boil:"file_integrity_weak" json:"file_integrity_weak,omitempty" toml:"file_integrity_weak" yaml:"file_integrity_weak,omitempty"`
	// Date last modified attribute saved to file
	FileLastModified null.Time `boil:"file_last_modified" json:"file_last_modified,omitempty" toml:"file_last_modified" yaml:"file_last_modified,omitempty"`
	// Computer platform
	Platform null.String `boil:"platform" json:"platform,omitempty" toml:"platform" yaml:"platform,omitempty"`
	// Category
	Section null.String `boil:"section" json:"section,omitempty" toml:"section" yaml:"section,omitempty"`
	// Description
	Comment null.String `boil:"comment" json:"comment,omitempty" toml:"comment" yaml:"comment,omitempty"`
	// Timestamp when record was created
	Createdat null.Time `boil:"createdat" json:"createdat,omitempty" toml:"createdat" yaml:"createdat,omitempty"`
	// Timestamp when record was revised
	Updatedat null.Time `boil:"updatedat" json:"updatedat,omitempty" toml:"updatedat" yaml:"updatedat,omitempty"`
	// Timestamp used to ignore record
	Deletedat null.Time `boil:"deletedat" json:"deletedat,omitempty" toml:"deletedat" yaml:"deletedat,omitempty"`
	// UUID of the user who last updated this record
	Updatedby null.String `boil:"updatedby" json:"updatedby,omitempty" toml:"updatedby" yaml:"updatedby,omitempty"`
	// UUID of the user who removed this record
	Deletedby null.String `boil:"deletedby" json:"deletedby,omitempty" toml:"deletedby" yaml:"deletedby,omitempty"`
	// Text file contained in archive to display
	RetrotxtReadme null.String `boil:"retrotxt_readme" json:"retrotxt_readme,omitempty" toml:"retrotxt_readme" yaml:"retrotxt_readme,omitempty"`
	// Disable the use of RetroTxt
	RetrotxtNoReadme null.Int8 `boil:"retrotxt_no_readme" json:"retrotxt_no_readme,omitempty" toml:"retrotxt_no_readme" yaml:"retrotxt_no_readme,omitempty"`
	// Program contained in archive to run in DOSBox
	DoseeRunProgram null.String `boil:"dosee_run_program" json:"dosee_run_program,omitempty" toml:"dosee_run_program" yaml:"dosee_run_program,omitempty"`
	// DOSee turn off expanded memory (EMS)
	DoseeHardwareCPU null.String `boil:"dosee_hardware_cpu" json:"dosee_hardware_cpu,omitempty" toml:"dosee_hardware_cpu" yaml:"dosee_hardware_cpu,omitempty"`
	// DOSee graphics/machine override
	DoseeHardwareGraphic null.String `boil:"dosee_hardware_graphic" json:"dosee_hardware_graphic,omitempty" toml:"dosee_hardware_graphic" yaml:"dosee_hardware_graphic,omitempty"`
	// DOSee audio override
	DoseeHardwareAudio null.String `boil:"dosee_hardware_audio" json:"dosee_hardware_audio,omitempty" toml:"dosee_hardware_audio" yaml:"dosee_hardware_audio,omitempty"`
	// DOSee disable aspect ratio corrections
	DoseeNoAspectRatioFix null.Int8 `boil:"dosee_no_aspect_ratio_fix" json:"dosee_no_aspect_ratio_fix,omitempty" toml:"dosee_no_aspect_ratio_fix" yaml:"dosee_no_aspect_ratio_fix,omitempty"`
	// Flag DOS program as incompatible for DOSBox
	DoseeIncompatible null.Int8 `boil:"dosee_incompatible" json:"dosee_incompatible,omitempty" toml:"dosee_incompatible" yaml:"dosee_incompatible,omitempty"`
	// DOSBox turn off EMS
	DoseeNoEms null.Int8 `boil:"dosee_no_ems" json:"dosee_no_ems,omitempty" toml:"dosee_no_ems" yaml:"dosee_no_ems,omitempty"`
	// DOSee turn off extended memory (XMS)
	DoseeNoXMS null.Int8 `boil:"dosee_no_xms" json:"dosee_no_xms,omitempty" toml:"dosee_no_xms" yaml:"dosee_no_xms,omitempty"`
	// DOSee turn off upper memory block access (UMB)
	DoseeNoUmb null.Int8 `boil:"dosee_no_umb" json:"dosee_no_umb,omitempty" toml:"dosee_no_umb" yaml:"dosee_no_umb,omitempty"`
	// DOSee load utilities
	DoseeLoadUtilities null.Int8 `boil:"dosee_load_utilities" json:"dosee_load_utilities,omitempty" toml:"dosee_load_utilities" yaml:"dosee_load_utilities,omitempty"`

	R *fileR `boil:"-" json:"-" toml:"-" yaml:"-"`
	L fileL  `boil:"-" json:"-" toml:"-" yaml:"-"`
}

var FileColumns = struct {
	ID                    string
	UUID                  string
	ListRelations         string
	WebID16colors         string
	WebIDGithub           string
	WebIDYoutube          string
	WebIDPouet            string
	WebIDDemozoo          string
	GroupBrandFor         string
	GroupBrandBy          string
	RecordTitle           string
	DateIssuedYear        string
	DateIssuedMonth       string
	DateIssuedDay         string
	CreditText            string
	CreditProgram         string
	CreditIllustration    string
	CreditAudio           string
	Filename              string
	Filesize              string
	ListLinks             string
	FileSecurityAlertURL  string
	FileZipContent        string
	FileMagicType         string
	PreviewImage          string
	FileIntegrityStrong   string
	FileIntegrityWeak     string
	FileLastModified      string
	Platform              string
	Section               string
	Comment               string
	Createdat             string
	Updatedat             string
	Deletedat             string
	Updatedby             string
	Deletedby             string
	RetrotxtReadme        string
	RetrotxtNoReadme      string
	DoseeRunProgram       string
	DoseeHardwareCPU      string
	DoseeHardwareGraphic  string
	DoseeHardwareAudio    string
	DoseeNoAspectRatioFix string
	DoseeIncompatible     string
	DoseeNoEms            string
	DoseeNoXMS            string
	DoseeNoUmb            string
	DoseeLoadUtilities    string
}{
	ID:                    "id",
	UUID:                  "uuid",
	ListRelations:         "list_relations",
	WebID16colors:         "web_id_16colors",
	WebIDGithub:           "web_id_github",
	WebIDYoutube:          "web_id_youtube",
	WebIDPouet:            "web_id_pouet",
	WebIDDemozoo:          "web_id_demozoo",
	GroupBrandFor:         "group_brand_for",
	GroupBrandBy:          "group_brand_by",
	RecordTitle:           "record_title",
	DateIssuedYear:        "date_issued_year",
	DateIssuedMonth:       "date_issued_month",
	DateIssuedDay:         "date_issued_day",
	CreditText:            "credit_text",
	CreditProgram:         "credit_program",
	CreditIllustration:    "credit_illustration",
	CreditAudio:           "credit_audio",
	Filename:              "filename",
	Filesize:              "filesize",
	ListLinks:             "list_links",
	FileSecurityAlertURL:  "file_security_alert_url",
	FileZipContent:        "file_zip_content",
	FileMagicType:         "file_magic_type",
	PreviewImage:          "preview_image",
	FileIntegrityStrong:   "file_integrity_strong",
	FileIntegrityWeak:     "file_integrity_weak",
	FileLastModified:      "file_last_modified",
	Platform:              "platform",
	Section:               "section",
	Comment:               "comment",
	Createdat:             "createdat",
	Updatedat:             "updatedat",
	Deletedat:             "deletedat",
	Updatedby:             "updatedby",
	Deletedby:             "deletedby",
	RetrotxtReadme:        "retrotxt_readme",
	RetrotxtNoReadme:      "retrotxt_no_readme",
	DoseeRunProgram:       "dosee_run_program",
	DoseeHardwareCPU:      "dosee_hardware_cpu",
	DoseeHardwareGraphic:  "dosee_hardware_graphic",
	DoseeHardwareAudio:    "dosee_hardware_audio",
	DoseeNoAspectRatioFix: "dosee_no_aspect_ratio_fix",
	DoseeIncompatible:     "dosee_incompatible",
	DoseeNoEms:            "dosee_no_ems",
	DoseeNoXMS:            "dosee_no_xms",
	DoseeNoUmb:            "dosee_no_umb",
	DoseeLoadUtilities:    "dosee_load_utilities",
}

var FileTableColumns = struct {
	ID                    string
	UUID                  string
	ListRelations         string
	WebID16colors         string
	WebIDGithub           string
	WebIDYoutube          string
	WebIDPouet            string
	WebIDDemozoo          string
	GroupBrandFor         string
	GroupBrandBy          string
	RecordTitle           string
	DateIssuedYear        string
	DateIssuedMonth       string
	DateIssuedDay         string
	CreditText            string
	CreditProgram         string
	CreditIllustration    string
	CreditAudio           string
	Filename              string
	Filesize              string
	ListLinks             string
	FileSecurityAlertURL  string
	FileZipContent        string
	FileMagicType         string
	PreviewImage          string
	FileIntegrityStrong   string
	FileIntegrityWeak     string
	FileLastModified      string
	Platform              string
	Section               string
	Comment               string
	Createdat             string
	Updatedat             string
	Deletedat             string
	Updatedby             string
	Deletedby             string
	RetrotxtReadme        string
	RetrotxtNoReadme      string
	DoseeRunProgram       string
	DoseeHardwareCPU      string
	DoseeHardwareGraphic  string
	DoseeHardwareAudio    string
	DoseeNoAspectRatioFix string
	DoseeIncompatible     string
	DoseeNoEms            string
	DoseeNoXMS            string
	DoseeNoUmb            string
	DoseeLoadUtilities    string
}{
	ID:                    "files.id",
	UUID:                  "files.uuid",
	ListRelations:         "files.list_relations",
	WebID16colors:         "files.web_id_16colors",
	WebIDGithub:           "files.web_id_github",
	WebIDYoutube:          "files.web_id_youtube",
	WebIDPouet:            "files.web_id_pouet",
	WebIDDemozoo:          "files.web_id_demozoo",
	GroupBrandFor:         "files.group_brand_for",
	GroupBrandBy:          "files.group_brand_by",
	RecordTitle:           "files.record_title",
	DateIssuedYear:        "files.date_issued_year",
	DateIssuedMonth:       "files.date_issued_month",
	DateIssuedDay:         "files.date_issued_day",
	CreditText:            "files.credit_text",
	CreditProgram:         "files.credit_program",
	CreditIllustration:    "files.credit_illustration",
	CreditAudio:           "files.credit_audio",
	Filename:              "files.filename",
	Filesize:              "files.filesize",
	ListLinks:             "files.list_links",
	FileSecurityAlertURL:  "files.file_security_alert_url",
	FileZipContent:        "files.file_zip_content",
	FileMagicType:         "files.file_magic_type",
	PreviewImage:          "files.preview_image",
	FileIntegrityStrong:   "files.file_integrity_strong",
	FileIntegrityWeak:     "files.file_integrity_weak",
	FileLastModified:      "files.file_last_modified",
	Platform:              "files.platform",
	Section:               "files.section",
	Comment:               "files.comment",
	Createdat:             "files.createdat",
	Updatedat:             "files.updatedat",
	Deletedat:             "files.deletedat",
	Updatedby:             "files.updatedby",
	Deletedby:             "files.deletedby",
	RetrotxtReadme:        "files.retrotxt_readme",
	RetrotxtNoReadme:      "files.retrotxt_no_readme",
	DoseeRunProgram:       "files.dosee_run_program",
	DoseeHardwareCPU:      "files.dosee_hardware_cpu",
	DoseeHardwareGraphic:  "files.dosee_hardware_graphic",
	DoseeHardwareAudio:    "files.dosee_hardware_audio",
	DoseeNoAspectRatioFix: "files.dosee_no_aspect_ratio_fix",
	DoseeIncompatible:     "files.dosee_incompatible",
	DoseeNoEms:            "files.dosee_no_ems",
	DoseeNoXMS:            "files.dosee_no_xms",
	DoseeNoUmb:            "files.dosee_no_umb",
	DoseeLoadUtilities:    "files.dosee_load_utilities",
}

// Generated where

type whereHelperint struct{ field string }

func (w whereHelperint) EQ(x int) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.EQ, x) }
func (w whereHelperint) NEQ(x int) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.NEQ, x) }
func (w whereHelperint) LT(x int) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.LT, x) }
func (w whereHelperint) LTE(x int) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.LTE, x) }
func (w whereHelperint) GT(x int) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.GT, x) }
func (w whereHelperint) GTE(x int) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.GTE, x) }
func (w whereHelperint) IN(slice []int) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelperint) NIN(slice []int) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

type whereHelpernull_String struct{ field string }

func (w whereHelpernull_String) EQ(x null.String) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_String) NEQ(x null.String) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_String) LT(x null.String) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_String) LTE(x null.String) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_String) GT(x null.String) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_String) GTE(x null.String) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}
func (w whereHelpernull_String) LIKE(x null.String) qm.QueryMod {
	return qm.Where(w.field+" LIKE ?", x)
}
func (w whereHelpernull_String) NLIKE(x null.String) qm.QueryMod {
	return qm.Where(w.field+" NOT LIKE ?", x)
}
func (w whereHelpernull_String) IN(slice []string) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelpernull_String) NIN(slice []string) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

func (w whereHelpernull_String) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_String) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }

type whereHelpernull_Int struct{ field string }

func (w whereHelpernull_Int) EQ(x null.Int) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_Int) NEQ(x null.Int) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_Int) LT(x null.Int) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_Int) LTE(x null.Int) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_Int) GT(x null.Int) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_Int) GTE(x null.Int) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}
func (w whereHelpernull_Int) IN(slice []int) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelpernull_Int) NIN(slice []int) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

func (w whereHelpernull_Int) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_Int) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }

type whereHelpernull_Int16 struct{ field string }

func (w whereHelpernull_Int16) EQ(x null.Int16) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_Int16) NEQ(x null.Int16) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_Int16) LT(x null.Int16) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_Int16) LTE(x null.Int16) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_Int16) GT(x null.Int16) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_Int16) GTE(x null.Int16) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}
func (w whereHelpernull_Int16) IN(slice []int16) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelpernull_Int16) NIN(slice []int16) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

func (w whereHelpernull_Int16) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_Int16) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }

type whereHelpernull_Int8 struct{ field string }

func (w whereHelpernull_Int8) EQ(x null.Int8) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_Int8) NEQ(x null.Int8) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_Int8) LT(x null.Int8) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_Int8) LTE(x null.Int8) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_Int8) GT(x null.Int8) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_Int8) GTE(x null.Int8) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}
func (w whereHelpernull_Int8) IN(slice []int8) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelpernull_Int8) NIN(slice []int8) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

func (w whereHelpernull_Int8) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_Int8) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }

type whereHelpernull_Time struct{ field string }

func (w whereHelpernull_Time) EQ(x null.Time) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_Time) NEQ(x null.Time) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_Time) LT(x null.Time) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_Time) LTE(x null.Time) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_Time) GT(x null.Time) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_Time) GTE(x null.Time) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}

func (w whereHelpernull_Time) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_Time) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }

var FileWhere = struct {
	ID                    whereHelperint
	UUID                  whereHelpernull_String
	ListRelations         whereHelpernull_String
	WebID16colors         whereHelpernull_String
	WebIDGithub           whereHelpernull_String
	WebIDYoutube          whereHelpernull_String
	WebIDPouet            whereHelpernull_Int
	WebIDDemozoo          whereHelpernull_Int
	GroupBrandFor         whereHelpernull_String
	GroupBrandBy          whereHelpernull_String
	RecordTitle           whereHelpernull_String
	DateIssuedYear        whereHelpernull_Int16
	DateIssuedMonth       whereHelpernull_Int8
	DateIssuedDay         whereHelpernull_Int8
	CreditText            whereHelpernull_String
	CreditProgram         whereHelpernull_String
	CreditIllustration    whereHelpernull_String
	CreditAudio           whereHelpernull_String
	Filename              whereHelpernull_String
	Filesize              whereHelpernull_Int
	ListLinks             whereHelpernull_String
	FileSecurityAlertURL  whereHelpernull_String
	FileZipContent        whereHelpernull_String
	FileMagicType         whereHelpernull_String
	PreviewImage          whereHelpernull_String
	FileIntegrityStrong   whereHelpernull_String
	FileIntegrityWeak     whereHelpernull_String
	FileLastModified      whereHelpernull_Time
	Platform              whereHelpernull_String
	Section               whereHelpernull_String
	Comment               whereHelpernull_String
	Createdat             whereHelpernull_Time
	Updatedat             whereHelpernull_Time
	Deletedat             whereHelpernull_Time
	Updatedby             whereHelpernull_String
	Deletedby             whereHelpernull_String
	RetrotxtReadme        whereHelpernull_String
	RetrotxtNoReadme      whereHelpernull_Int8
	DoseeRunProgram       whereHelpernull_String
	DoseeHardwareCPU      whereHelpernull_String
	DoseeHardwareGraphic  whereHelpernull_String
	DoseeHardwareAudio    whereHelpernull_String
	DoseeNoAspectRatioFix whereHelpernull_Int8
	DoseeIncompatible     whereHelpernull_Int8
	DoseeNoEms            whereHelpernull_Int8
	DoseeNoXMS            whereHelpernull_Int8
	DoseeNoUmb            whereHelpernull_Int8
	DoseeLoadUtilities    whereHelpernull_Int8
}{
	ID:                    whereHelperint{field: "`files`.`id`"},
	UUID:                  whereHelpernull_String{field: "`files`.`uuid`"},
	ListRelations:         whereHelpernull_String{field: "`files`.`list_relations`"},
	WebID16colors:         whereHelpernull_String{field: "`files`.`web_id_16colors`"},
	WebIDGithub:           whereHelpernull_String{field: "`files`.`web_id_github`"},
	WebIDYoutube:          whereHelpernull_String{field: "`files`.`web_id_youtube`"},
	WebIDPouet:            whereHelpernull_Int{field: "`files`.`web_id_pouet`"},
	WebIDDemozoo:          whereHelpernull_Int{field: "`files`.`web_id_demozoo`"},
	GroupBrandFor:         whereHelpernull_String{field: "`files`.`group_brand_for`"},
	GroupBrandBy:          whereHelpernull_String{field: "`files`.`group_brand_by`"},
	RecordTitle:           whereHelpernull_String{field: "`files`.`record_title`"},
	DateIssuedYear:        whereHelpernull_Int16{field: "`files`.`date_issued_year`"},
	DateIssuedMonth:       whereHelpernull_Int8{field: "`files`.`date_issued_month`"},
	DateIssuedDay:         whereHelpernull_Int8{field: "`files`.`date_issued_day`"},
	CreditText:            whereHelpernull_String{field: "`files`.`credit_text`"},
	CreditProgram:         whereHelpernull_String{field: "`files`.`credit_program`"},
	CreditIllustration:    whereHelpernull_String{field: "`files`.`credit_illustration`"},
	CreditAudio:           whereHelpernull_String{field: "`files`.`credit_audio`"},
	Filename:              whereHelpernull_String{field: "`files`.`filename`"},
	Filesize:              whereHelpernull_Int{field: "`files`.`filesize`"},
	ListLinks:             whereHelpernull_String{field: "`files`.`list_links`"},
	FileSecurityAlertURL:  whereHelpernull_String{field: "`files`.`file_security_alert_url`"},
	FileZipContent:        whereHelpernull_String{field: "`files`.`file_zip_content`"},
	FileMagicType:         whereHelpernull_String{field: "`files`.`file_magic_type`"},
	PreviewImage:          whereHelpernull_String{field: "`files`.`preview_image`"},
	FileIntegrityStrong:   whereHelpernull_String{field: "`files`.`file_integrity_strong`"},
	FileIntegrityWeak:     whereHelpernull_String{field: "`files`.`file_integrity_weak`"},
	FileLastModified:      whereHelpernull_Time{field: "`files`.`file_last_modified`"},
	Platform:              whereHelpernull_String{field: "`files`.`platform`"},
	Section:               whereHelpernull_String{field: "`files`.`section`"},
	Comment:               whereHelpernull_String{field: "`files`.`comment`"},
	Createdat:             whereHelpernull_Time{field: "`files`.`createdat`"},
	Updatedat:             whereHelpernull_Time{field: "`files`.`updatedat`"},
	Deletedat:             whereHelpernull_Time{field: "`files`.`deletedat`"},
	Updatedby:             whereHelpernull_String{field: "`files`.`updatedby`"},
	Deletedby:             whereHelpernull_String{field: "`files`.`deletedby`"},
	RetrotxtReadme:        whereHelpernull_String{field: "`files`.`retrotxt_readme`"},
	RetrotxtNoReadme:      whereHelpernull_Int8{field: "`files`.`retrotxt_no_readme`"},
	DoseeRunProgram:       whereHelpernull_String{field: "`files`.`dosee_run_program`"},
	DoseeHardwareCPU:      whereHelpernull_String{field: "`files`.`dosee_hardware_cpu`"},
	DoseeHardwareGraphic:  whereHelpernull_String{field: "`files`.`dosee_hardware_graphic`"},
	DoseeHardwareAudio:    whereHelpernull_String{field: "`files`.`dosee_hardware_audio`"},
	DoseeNoAspectRatioFix: whereHelpernull_Int8{field: "`files`.`dosee_no_aspect_ratio_fix`"},
	DoseeIncompatible:     whereHelpernull_Int8{field: "`files`.`dosee_incompatible`"},
	DoseeNoEms:            whereHelpernull_Int8{field: "`files`.`dosee_no_ems`"},
	DoseeNoXMS:            whereHelpernull_Int8{field: "`files`.`dosee_no_xms`"},
	DoseeNoUmb:            whereHelpernull_Int8{field: "`files`.`dosee_no_umb`"},
	DoseeLoadUtilities:    whereHelpernull_Int8{field: "`files`.`dosee_load_utilities`"},
}

// FileRels is where relationship names are stored.
var FileRels = struct {
}{}

// fileR is where relationships are stored.
type fileR struct {
}

// NewStruct creates a new relationship struct
func (*fileR) NewStruct() *fileR {
	return &fileR{}
}

// fileL is where Load methods for each relationship are stored.
type fileL struct{}

var (
	fileAllColumns            = []string{"id", "uuid", "list_relations", "web_id_16colors", "web_id_github", "web_id_youtube", "web_id_pouet", "web_id_demozoo", "group_brand_for", "group_brand_by", "record_title", "date_issued_year", "date_issued_month", "date_issued_day", "credit_text", "credit_program", "credit_illustration", "credit_audio", "filename", "filesize", "list_links", "file_security_alert_url", "file_zip_content", "file_magic_type", "preview_image", "file_integrity_strong", "file_integrity_weak", "file_last_modified", "platform", "section", "comment", "createdat", "updatedat", "deletedat", "updatedby", "deletedby", "retrotxt_readme", "retrotxt_no_readme", "dosee_run_program", "dosee_hardware_cpu", "dosee_hardware_graphic", "dosee_hardware_audio", "dosee_no_aspect_ratio_fix", "dosee_incompatible", "dosee_no_ems", "dosee_no_xms", "dosee_no_umb", "dosee_load_utilities"}
	fileColumnsWithoutDefault = []string{"list_relations", "web_id_16colors", "web_id_github", "web_id_youtube", "web_id_pouet", "web_id_demozoo", "group_brand_for", "group_brand_by", "record_title", "date_issued_year", "date_issued_month", "date_issued_day", "credit_text", "credit_program", "credit_illustration", "credit_audio", "filename", "filesize", "list_links", "file_security_alert_url", "file_zip_content", "file_magic_type", "preview_image", "file_integrity_strong", "file_integrity_weak", "file_last_modified", "platform", "section", "comment", "createdat", "updatedat", "deletedat", "updatedby", "deletedby", "retrotxt_readme", "retrotxt_no_readme", "dosee_run_program", "dosee_hardware_cpu", "dosee_hardware_graphic", "dosee_hardware_audio", "dosee_no_aspect_ratio_fix", "dosee_incompatible", "dosee_no_ems", "dosee_no_xms", "dosee_no_umb", "dosee_load_utilities"}
	fileColumnsWithDefault    = []string{"id", "uuid"}
	filePrimaryKeyColumns     = []string{"id"}
	fileGeneratedColumns      = []string{}
)

type (
	// FileSlice is an alias for a slice of pointers to File.
	// This should almost always be used instead of []File.
	FileSlice []*File

	fileQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	fileType                 = reflect.TypeOf(&File{})
	fileMapping              = queries.MakeStructMapping(fileType)
	filePrimaryKeyMapping, _ = queries.BindMapping(fileType, fileMapping, filePrimaryKeyColumns)
	fileInsertCacheMut       sync.RWMutex
	fileInsertCache          = make(map[string]insertCache)
	fileUpdateCacheMut       sync.RWMutex
	fileUpdateCache          = make(map[string]updateCache)
	fileUpsertCacheMut       sync.RWMutex
	fileUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force qmhelper dependency for where clause generation (which doesn't
	// always happen)
	_ = qmhelper.Where
)

// One returns a single file record from the query.
func (q fileQuery) One(ctx context.Context, exec boil.ContextExecutor) (*File, error) {
	o := &File{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(ctx, exec, o)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: failed to execute a one query for files")
	}

	return o, nil
}

// All returns all File records from the query.
func (q fileQuery) All(ctx context.Context, exec boil.ContextExecutor) (FileSlice, error) {
	var o []*File

	err := q.Bind(ctx, exec, &o)
	if err != nil {
		return nil, errors.Wrap(err, "models: failed to assign all query results to File slice")
	}

	return o, nil
}

// Count returns the count of all File records in the query.
func (q fileQuery) Count(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to count files rows")
	}

	return count, nil
}

// Exists checks if the row exists in the table.
func (q fileQuery) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "models: failed to check if files exists")
	}

	return count > 0, nil
}

// Files retrieves all the records using an executor.
func Files(mods ...qm.QueryMod) fileQuery {
	mods = append(mods, qm.From("`files`"), qmhelper.WhereIsNull("`files`.`deletedat`"))
	q := NewQuery(mods...)
	if len(queries.GetSelect(q)) == 0 {
		queries.SetSelect(q, []string{"`files`.*"})
	}

	return fileQuery{q}
}

// FindFile retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindFile(ctx context.Context, exec boil.ContextExecutor, iD int, selectCols ...string) (*File, error) {
	fileObj := &File{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from `files` where `id`=? and `deletedat` is null", sel,
	)

	q := queries.Raw(query, iD)

	err := q.Bind(ctx, exec, fileObj)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: unable to select from files")
	}

	return fileObj, nil
}

// Insert a single record using an executor.
// See boil.Columns.InsertColumnSet documentation to understand column list inference for inserts.
func (o *File) Insert(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {
	if o == nil {
		return errors.New("models: no files provided for insertion")
	}

	var err error
	if !boil.TimestampsAreSkipped(ctx) {
		currTime := time.Now().In(boil.GetLocation())

		if queries.MustTime(o.Createdat).IsZero() {
			queries.SetScanner(&o.Createdat, currTime)
		}
		if queries.MustTime(o.Updatedat).IsZero() {
			queries.SetScanner(&o.Updatedat, currTime)
		}
	}

	nzDefaults := queries.NonZeroDefaultSet(fileColumnsWithDefault, o)

	key := makeCacheKey(columns, nzDefaults)
	fileInsertCacheMut.RLock()
	cache, cached := fileInsertCache[key]
	fileInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := columns.InsertColumnSet(
			fileAllColumns,
			fileColumnsWithDefault,
			fileColumnsWithoutDefault,
			nzDefaults,
		)

		cache.valueMapping, err = queries.BindMapping(fileType, fileMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(fileType, fileMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO `files` (`%s`) %%sVALUES (%s)%%s", strings.Join(wl, "`,`"), strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO `files` () VALUES ()%s%s"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			cache.retQuery = fmt.Sprintf("SELECT `%s` FROM `files` WHERE %s", strings.Join(returnColumns, "`,`"), strmangle.WhereClause("`", "`", 0, filePrimaryKeyColumns))
		}

		cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}
	result, err := exec.ExecContext(ctx, cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "models: unable to insert into files")
	}

	var lastID int64
	var identifierCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	lastID, err = result.LastInsertId()
	if err != nil {
		return ErrSyncFail
	}

	o.ID = int(lastID)
	if lastID != 0 && len(cache.retMapping) == 1 && cache.retMapping[0] == fileMapping["id"] {
		goto CacheNoHooks
	}

	identifierCols = []interface{}{
		o.ID,
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.retQuery)
		fmt.Fprintln(writer, identifierCols...)
	}
	err = exec.QueryRowContext(ctx, cache.retQuery, identifierCols...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	if err != nil {
		return errors.Wrap(err, "models: unable to populate default values for files")
	}

CacheNoHooks:
	if !cached {
		fileInsertCacheMut.Lock()
		fileInsertCache[key] = cache
		fileInsertCacheMut.Unlock()
	}

	return nil
}

// Update uses an executor to update the File.
// See boil.Columns.UpdateColumnSet documentation to understand column list inference for updates.
// Update does not automatically update the record in case of default values. Use .Reload() to refresh the records.
func (o *File) Update(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {
	if !boil.TimestampsAreSkipped(ctx) {
		currTime := time.Now().In(boil.GetLocation())

		queries.SetScanner(&o.Updatedat, currTime)
	}

	var err error
	key := makeCacheKey(columns, nil)
	fileUpdateCacheMut.RLock()
	cache, cached := fileUpdateCache[key]
	fileUpdateCacheMut.RUnlock()

	if !cached {
		wl := columns.UpdateColumnSet(
			fileAllColumns,
			filePrimaryKeyColumns,
		)

		if !columns.IsWhitelist() {
			wl = strmangle.SetComplement(wl, []string{"created_at"})
		}
		if len(wl) == 0 {
			return 0, errors.New("models: unable to update files, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE `files` SET %s WHERE %s",
			strmangle.SetParamNames("`", "`", 0, wl),
			strmangle.WhereClause("`", "`", 0, filePrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(fileType, fileMapping, append(wl, filePrimaryKeyColumns...))
		if err != nil {
			return 0, err
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, values)
	}
	var result sql.Result
	result, err = exec.ExecContext(ctx, cache.query, values...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update files row")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by update for files")
	}

	if !cached {
		fileUpdateCacheMut.Lock()
		fileUpdateCache[key] = cache
		fileUpdateCacheMut.Unlock()
	}

	return rowsAff, nil
}

// UpdateAll updates all rows with the specified column values.
func (q fileQuery) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	queries.SetUpdate(q.Query, cols)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update all for files")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to retrieve rows affected for files")
	}

	return rowsAff, nil
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o FileSlice) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	ln := int64(len(o))
	if ln == 0 {
		return 0, nil
	}

	if len(cols) == 0 {
		return 0, errors.New("models: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), filePrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE `files` SET %s WHERE %s",
		strmangle.SetParamNames("`", "`", 0, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, filePrimaryKeyColumns, len(o)))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update all in file slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to retrieve rows affected all in update all file")
	}
	return rowsAff, nil
}

var mySQLFileUniqueColumns = []string{
	"id",
}

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
// See boil.Columns documentation for how to properly use updateColumns and insertColumns.
func (o *File) Upsert(ctx context.Context, exec boil.ContextExecutor, updateColumns, insertColumns boil.Columns) error {
	if o == nil {
		return errors.New("models: no files provided for upsert")
	}
	if !boil.TimestampsAreSkipped(ctx) {
		currTime := time.Now().In(boil.GetLocation())

		if queries.MustTime(o.Createdat).IsZero() {
			queries.SetScanner(&o.Createdat, currTime)
		}
		queries.SetScanner(&o.Updatedat, currTime)
	}

	nzDefaults := queries.NonZeroDefaultSet(fileColumnsWithDefault, o)
	nzUniques := queries.NonZeroDefaultSet(mySQLFileUniqueColumns, o)

	if len(nzUniques) == 0 {
		return errors.New("cannot upsert with a table that cannot conflict on a unique column")
	}

	// Build cache key in-line uglily - mysql vs psql problems
	buf := strmangle.GetBuffer()
	buf.WriteString(strconv.Itoa(updateColumns.Kind))
	for _, c := range updateColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(insertColumns.Kind))
	for _, c := range insertColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzUniques {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	fileUpsertCacheMut.RLock()
	cache, cached := fileUpsertCache[key]
	fileUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, _ := insertColumns.InsertColumnSet(
			fileAllColumns,
			fileColumnsWithDefault,
			fileColumnsWithoutDefault,
			nzDefaults,
		)

		update := updateColumns.UpdateColumnSet(
			fileAllColumns,
			filePrimaryKeyColumns,
		)

		if !updateColumns.IsNone() && len(update) == 0 {
			return errors.New("models: unable to upsert files, could not build update column list")
		}

		ret := strmangle.SetComplement(fileAllColumns, strmangle.SetIntersect(insert, update))

		cache.query = buildUpsertQueryMySQL(dialect, "`files`", update, insert)
		cache.retQuery = fmt.Sprintf(
			"SELECT %s FROM `files` WHERE %s",
			strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, ret), ","),
			strmangle.WhereClause("`", "`", 0, nzUniques),
		)

		cache.valueMapping, err = queries.BindMapping(fileType, fileMapping, insert)
		if err != nil {
			return err
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(fileType, fileMapping, ret)
			if err != nil {
				return err
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}
	result, err := exec.ExecContext(ctx, cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "models: unable to upsert for files")
	}

	var lastID int64
	var uniqueMap []uint64
	var nzUniqueCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	lastID, err = result.LastInsertId()
	if err != nil {
		return ErrSyncFail
	}

	o.ID = int(lastID)
	if lastID != 0 && len(cache.retMapping) == 1 && cache.retMapping[0] == fileMapping["id"] {
		goto CacheNoHooks
	}

	uniqueMap, err = queries.BindMapping(fileType, fileMapping, nzUniques)
	if err != nil {
		return errors.Wrap(err, "models: unable to retrieve unique values for files")
	}
	nzUniqueCols = queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), uniqueMap)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.retQuery)
		fmt.Fprintln(writer, nzUniqueCols...)
	}
	err = exec.QueryRowContext(ctx, cache.retQuery, nzUniqueCols...).Scan(returns...)
	if err != nil {
		return errors.Wrap(err, "models: unable to populate default values for files")
	}

CacheNoHooks:
	if !cached {
		fileUpsertCacheMut.Lock()
		fileUpsertCache[key] = cache
		fileUpsertCacheMut.Unlock()
	}

	return nil
}

// Delete deletes a single File record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *File) Delete(ctx context.Context, exec boil.ContextExecutor, hardDelete bool) (int64, error) {
	if o == nil {
		return 0, errors.New("models: no File provided for delete")
	}

	var (
		sql  string
		args []interface{}
	)
	if hardDelete {
		args = queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), filePrimaryKeyMapping)
		sql = "DELETE FROM `files` WHERE `id`=?"
	} else {
		currTime := time.Now().In(boil.GetLocation())
		o.Deletedat = null.TimeFrom(currTime)
		wl := []string{"deletedat"}
		sql = fmt.Sprintf("UPDATE `files` SET %s WHERE `id`=?",
			strmangle.SetParamNames("`", "`", 0, wl),
		)
		valueMapping, err := queries.BindMapping(fileType, fileMapping, append(wl, filePrimaryKeyColumns...))
		if err != nil {
			return 0, err
		}
		args = queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), valueMapping)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete from files")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by delete for files")
	}

	return rowsAff, nil
}

// DeleteAll deletes all matching rows.
func (q fileQuery) DeleteAll(ctx context.Context, exec boil.ContextExecutor, hardDelete bool) (int64, error) {
	if q.Query == nil {
		return 0, errors.New("models: no fileQuery provided for delete all")
	}

	if hardDelete {
		queries.SetDelete(q.Query)
	} else {
		currTime := time.Now().In(boil.GetLocation())
		queries.SetUpdate(q.Query, M{"deletedat": currTime})
	}

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete all from files")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by deleteall for files")
	}

	return rowsAff, nil
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o FileSlice) DeleteAll(ctx context.Context, exec boil.ContextExecutor, hardDelete bool) (int64, error) {
	if len(o) == 0 {
		return 0, nil
	}

	var (
		sql  string
		args []interface{}
	)
	if hardDelete {
		for _, obj := range o {
			pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), filePrimaryKeyMapping)
			args = append(args, pkeyArgs...)
		}
		sql = "DELETE FROM `files` WHERE " +
			strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, filePrimaryKeyColumns, len(o))
	} else {
		currTime := time.Now().In(boil.GetLocation())
		for _, obj := range o {
			pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), filePrimaryKeyMapping)
			args = append(args, pkeyArgs...)
			obj.Deletedat = null.TimeFrom(currTime)
		}
		wl := []string{"deletedat"}
		sql = fmt.Sprintf("UPDATE `files` SET %s WHERE "+
			strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, filePrimaryKeyColumns, len(o)),
			strmangle.SetParamNames("`", "`", 0, wl),
		)
		args = append([]interface{}{currTime}, args...)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete all from file slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by deleteall for files")
	}

	return rowsAff, nil
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *File) Reload(ctx context.Context, exec boil.ContextExecutor) error {
	ret, err := FindFile(ctx, exec, o.ID)
	if err != nil {
		return err
	}

	*o = *ret
	return nil
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *FileSlice) ReloadAll(ctx context.Context, exec boil.ContextExecutor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	slice := FileSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), filePrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT `files`.* FROM `files` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, filePrimaryKeyColumns, len(*o)) +
		"and `deletedat` is null"

	q := queries.Raw(sql, args...)

	err := q.Bind(ctx, exec, &slice)
	if err != nil {
		return errors.Wrap(err, "models: unable to reload all in FileSlice")
	}

	*o = slice

	return nil
}

// FileExists checks if the File row exists.
func FileExists(ctx context.Context, exec boil.ContextExecutor, iD int) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from `files` where `id`=? and `deletedat` is null limit 1)"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, iD)
	}
	row := exec.QueryRowContext(ctx, sql, iD)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Wrap(err, "models: unable to check if files exists")
	}

	return exists, nil
}

// Exists checks if the File row exists.
func (o *File) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	return FileExists(ctx, exec, o.ID)
}
